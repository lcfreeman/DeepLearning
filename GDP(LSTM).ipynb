{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc061aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ea297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/GDP.csv')\n",
    "data.set_index('date',inplace=True)\n",
    "base = data.loc[2000]\n",
    "scaled_data = data/base\n",
    "years = data.index\n",
    "years = list(map(int,years))\n",
    "inputs = torch.tensor(scaled_data.iloc[:-1].values, dtype=torch.float32, device=device)\n",
    "labels = torch.tensor(scaled_data.iloc[1:].values, dtype=torch.float32, device=device)\n",
    "train_sequence = sum([i>=1970 and i<=2000 for i in years])\n",
    "test_sequence = sum([i>2000 for i in years])\n",
    "train_data = inputs[:train_sequence]\n",
    "train_label = labels[:train_sequence]\n",
    "test_data = inputs[train_sequence:]\n",
    "test_label = labels[train_sequence:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5513c11",
   "metadata": {},
   "source": [
    "# LSTMCell\n",
    "<img src=\"./data/LSTM.png\" width=\"600\" height=\"200\">\n",
    "$$\\mathrm{I}_t=\\sigma(W_i \\cdot x_t+U_i \\cdot h_{t-1}+b_i) $$\n",
    "$$\\mathrm{F}_t=\\sigma(W_f \\cdot x_t+U_f \\cdot h_{t-1}+b_f) $$\n",
    "$$\\mathrm{O}_t=\\sigma(W_o \\cdot x_t+U_o \\cdot h_{t-1}+b_o) $$\n",
    "$$\\mathrm{\\tilde{C}}_t=\\mathrm{tanh}(W_c \\cdot x_t+U_c \\cdot h_{t-1}+b_c) $$\n",
    "$$\\mathrm{{C}}_t=\\mathrm{{C}}_{t-1} \\cdot \\mathrm{F}_t + \\mathrm{\\tilde{C}}_t \\cdot \\mathrm{I}_t$$\n",
    "$$\\mathrm{{H}}_t=\\mathrm{O}_t \\cdot \\mathrm{tanh}(\\mathrm{{C}}_t)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e29d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,device):\n",
    "        super().__init__()\n",
    "        # input Matrix\n",
    "        self.W_f = nn.Linear(in_features=input_size,out_features=hidden_size,bias=False)\n",
    "        self.W_i = nn.Linear(in_features=input_size,out_features=hidden_size,bias=False)\n",
    "        self.W_c = nn.Linear(in_features=input_size,out_features=hidden_size,bias=False)\n",
    "        self.W_o = nn.Linear(in_features=input_size,out_features=hidden_size,bias=False)\n",
    "        # hidden Matrix\n",
    "        self.U_f = nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=False)\n",
    "        self.U_i = nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=False)\n",
    "        self.U_c = nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=False)\n",
    "        self.U_o = nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=False)\n",
    "        # bias\n",
    "        self.b_f = nn.Parameter(data=torch.zeros(hidden_size,device=device))\n",
    "        self.b_i = nn.Parameter(data=torch.zeros(hidden_size,device=device))\n",
    "        self.b_c = nn.Parameter(data=torch.zeros(hidden_size,device=device))\n",
    "        self.b_o = nn.Parameter(data=torch.zeros(hidden_size,device=device))\n",
    "        # activation\n",
    "        self.sigmf = nn.Sigmoid()\n",
    "        self.sigmi = nn.Sigmoid()\n",
    "        self.sigmo = nn.Sigmoid()\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        \n",
    "    def forward(self,x_t,h_p,c_p):\n",
    "        gate_f = self.sigmf(self.W_f(x_t)+self.U_f(h_p)+self.b_f)\n",
    "        gate_i = self.sigmi(self.W_i(x_t)+self.U_i(h_p)+self.b_i)\n",
    "        tidl_c = self.tanh1(self.W_c(x_t)+self.U_c(h_p)+self.b_c)\n",
    "        gate_o = self.sigmo(self.W_o(x_t)+self.U_o(h_p)+self.b_o)\n",
    "        #print(gate_f,gate_i,gate_o,tidl_c)\n",
    "         # Intermediate results for debugging\n",
    "        gate_f = gate_f.detach()  # Ensure c_p is not modified during the computation\n",
    "        tidl_c = tidl_c.detach()\n",
    "        c = gate_f*c_p+gate_i*tidl_c\n",
    "        gate_o = gate_o.detach()\n",
    "        c = c.detach()\n",
    "        h = gate_o*self.tanh2(c)\n",
    "        \n",
    "        return h,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,device,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.lstmforward = nn.ModuleList(LSTMCell(input_size=input_size if i==0 else hidden_size,\n",
    "                                                  hidden_size=hidden_size,device=self.device)\n",
    "                                         for i in range(self.num_layers))\n",
    "        #self.lstmbackward = nn.ModuleList(LSTMCell(input_size=input_size if i==0 else hidden_size,hidden_size=hidden_size)\n",
    "        #                                 for i in range(self.num_layers))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size, seq_len,_ = x.size()\n",
    "        h_forward = torch.zeros(self.num_layers,batch_size,self.hidden_size,device=x.device)\n",
    "        c_forward = torch.zeros(self.num_layers,batch_size,self.hidden_size,device=x.device)\n",
    "        outputs_forward = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:,t,:]\n",
    "            for i in range(self.num_layers):\n",
    "                h_forward[i],c_forward[i] = self.lstmforward[i](x_t,h_forward[i],c_forward[i])\n",
    "                x_t = h_forward[i]\n",
    "            outputs_forward.append(h_forward[-1])\n",
    "        out_forward = torch.stack(outputs_forward,dim=1) \n",
    "        # backward pass\n",
    "        #h_backward = torch.zeros(self.num_layers,batch_size,hidden_size)\n",
    "        #c_backward = torch.zeros(self.num_layers,batch_size,hidden_size)\n",
    "        #outputs_backward = []\n",
    "        #for t in range(seq_len):\n",
    "        #    x_t = x[:,seq_len-t-1,:]\n",
    "        #    for i in range(self.num_layers):\n",
    "        #        h_backward[i],c_backward[i] = self.lstmbackward[i](x_t,h_backward[i],c_backward[i])\n",
    "        #        x_t = h_backward[i]\n",
    "        #    outputs_backward.append(h_backward[-1])\n",
    "        #out_backward = torch.stack(outputs_backward[::-1],dim=1)    \n",
    "        #biout = torch.cat((out_forward,out_backward),dim=-1)\n",
    "            \n",
    "        return out_forward,(h_forward[-1],c_forward[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa7660",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "input_size = 10   # Number of input features\n",
    "hidden_size = 20  # Number of LSTM hidden units\n",
    "num_layers = 1    # Number of LSTM layers\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers)\n",
    "\n",
    "# Dummy input (batch_size=5, seq_length=7, input_size=10)\n",
    "inputs = torch.randn(5, 7, input_size)\n",
    "\n",
    "# Forward pass\n",
    "outputs, (hn, cn) = model(inputs)\n",
    "\n",
    "print(outputs.size())  # Should be (5, 7, hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c8677",
   "metadata": {},
   "source": [
    "# GRUCell\n",
    "<img src=\"./data/GRU.png\" width=\"600\" height=\"200\">\n",
    "$$\\mathrm{R}_t=\\sigma(W_r \\cdot x_t+U_r \\cdot h_{t-1}+b_r) $$\n",
    "$$\\mathrm{Z}_t=\\sigma(W_z \\cdot x_t+U_z \\cdot h_{t-1}+b_z) $$\n",
    "$$\\mathrm{\\tilde{H}}_t=\\mathrm{tanh}(W_h \\cdot x_t+U_h \\cdot (h_{t-1} \\cdot \\mathrm{R}_t)+b_h) $$\n",
    "$$\\mathrm{{H}}_t=h_{t-1} \\cdot \\mathrm{Z}_t + \\mathrm{\\tilde{H}}_t \\cdot (1-\\mathrm{Z}_t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,device):\n",
    "        super().__init__()\n",
    "        # input Matrix\n",
    "        self.W_r = nn.Linear(in_features=input_size,out_features=hidden_size,bias=False)\n",
    "        self.W_z = nn.Linear(in_features=input_size,out_features=hidden_size,bias=False)\n",
    "        self.W_h = nn.Linear(in_features=input_size,out_features=hidden_size,bias=False)\n",
    "        # hidden Matrix\n",
    "        self.U_r = nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=False)\n",
    "        self.U_z = nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=False)\n",
    "        self.U_h = nn.Linear(in_features=hidden_size,out_features=hidden_size,bias=False)\n",
    "        # bias\n",
    "        self.b_r = nn.Parameter(data=torch.zeros(hidden_size,device=device))\n",
    "        self.b_z = nn.Parameter(data=torch.zeros(hidden_size,device=device))\n",
    "        self.b_h = nn.Parameter(data=torch.zeros(hidden_size,device=device))\n",
    "        # activation\n",
    "        self.sigmr = nn.Sigmoid()\n",
    "        self.sigmz = nn.Sigmoid()\n",
    "        self.tanhh = nn.Tanh()\n",
    "        \n",
    "    def forward(self,x_t,h_p):\n",
    "        gate_r = self.sigmr(self.W_r(x_t)+self.U_r(h_p)+self.b_r)\n",
    "        gate_z = self.sigmz(self.W_z(x_t)+self.U_z(h_p)+self.b_z)\n",
    "        gate_r = gate_r.detach()\n",
    "        tidl_h = self.tanhh(self.W_h(x_t)+self.U_h(h_p*gate_r)+self.b_h)\n",
    "        gate_z = gate_z.detach()\n",
    "        h = h_p*gate_z+tidl_h*(1-gate_z)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,device,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.gruforward = nn.ModuleList(GRUCell(input_size=input_size if i==0 else hidden_size,\n",
    "                                                  hidden_size=hidden_size,device=self.device)\n",
    "                                         for i in range(self.num_layers))\n",
    "        #self.grubackward = nn.ModuleList(GRUCell(input_size=input_size if i==0 else hidden_size,hidden_size=hidden_size)\n",
    "        #                                 for i in range(self.num_layers))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size, seq_len,_ = x.size()\n",
    "        h_forward = torch.zeros(self.num_layers,batch_size,self.hidden_size,device=x.device)\n",
    "        c_forward = torch.zeros(self.num_layers,batch_size,self.hidden_size,device=x.device)\n",
    "        outputs_forward = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:,t,:]\n",
    "            for i in range(self.num_layers):\n",
    "                h_forward[i] = self.gruforward[i](x_t,h_forward[i])\n",
    "                x_t = h_forward[i]\n",
    "            outputs_forward.append(h_forward[-1])\n",
    "        out_forward = torch.stack(outputs_forward,dim=1) \n",
    "        # backward pass\n",
    "        #h_backward = torch.zeros(self.num_layers,batch_size,hidden_size)\n",
    "        #c_backward = torch.zeros(self.num_layers,batch_size,hidden_size)\n",
    "        #outputs_backward = []\n",
    "        #for t in range(seq_len):\n",
    "        #    x_t = x[:,seq_len-t-1,:]\n",
    "        #    for i in range(self.num_layers):\n",
    "        #        h_backward[i],c_backward[i] = self.grubackward[i](x_t,h_backward[i],c_backward[i])\n",
    "        #        x_t = h_backward[i]\n",
    "        #    outputs_backward.append(h_backward[-1])\n",
    "        #out_backward = torch.stack(outputs_backward[::-1],dim=1)    \n",
    "        #biout = torch.cat((out_forward,out_backward),dim=-1)\n",
    "            \n",
    "        return out_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897efc42",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "input_size = 10   # Number of input features\n",
    "hidden_size = 20  # Number of GRU hidden units\n",
    "num_layers = 1    # Number of GRU layers\n",
    "\n",
    "model = GRU(input_size, hidden_size, device,num_layers).to(device)\n",
    "\n",
    "# Dummy input (batch_size=5, seq_length=7, input_size=10)\n",
    "inputs = torch.randn(5, 7, input_size,device=device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(inputs)\n",
    "\n",
    "print(outputs.size())  # Should be (5, 7, hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf369e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a5765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aeac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super(Net,self).__init__()\n",
    "        self.rnn = LSTM(input_size=input_size,hidden_size=hidden_size,device=device)\n",
    "        self.fc = nn.Linear(hidden_size,1)\n",
    "    def forward(self,X):\n",
    "        X = X[:,:,None]\n",
    "        X, _ = self.rnn(X)\n",
    "        X = self.fc(X)\n",
    "        X = X[:,:,0]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df965f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size=1,hidden_size=5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ac801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steps = 50000\n",
    "#writer = SummaryWriter(log_dir='./log')\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=1000,gamma=0.1)\n",
    "for step in range(steps):\n",
    "    # train\n",
    "    train_data, train_label = train_data.to(device), train_label.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    train_output = model(train_data)\n",
    "    train_loss = criterion(train_output,train_label)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    for para_group in optimizer.param_groups:\n",
    "        current_lr = para_group['lr']\n",
    "    if (step+1)%1000==0:\n",
    "        print(f'{step+1}/{steps} lr={current_lr} train_loss={train_loss.item()}')\n",
    "        #writer.add_scalar('Loss/train',train_loss.item(),step+1)\n",
    "    #scheduler.step()\n",
    "    \n",
    "    # eval\n",
    "    if (step+1)%10000==0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_data, test_label = test_data.to(device), test_label.to(device)\n",
    "            test_output = model(test_data)\n",
    "            test_loss = criterion(test_output,test_label)\n",
    "            print(f'{step+1}/{steps} test_loss={test_loss.item()}')\n",
    "            #writer.add_scalar('Loss/test',test_loss.item(),step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcd6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aloha]",
   "language": "python",
   "name": "conda-env-aloha-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
